# LLM-Finetuning

# PEFT Fine-Tuning Project üöÄ

Welcome to the PEFT (Pretraining-Evaluation Fine-Tuning) project repository! This project focuses on efficiently fine-tuning large language models using LoRA and Hugging Face's transformers library.

<!-- ![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_overview.png) -->

## Fine Tuning Notebook Table üìë

| Notebook Title                                                                                               | Description                                                                                                                                                                                   | Colab Badge                                                                                                                                                                                                                         |
| ------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Efficiently Train Large Language Models with LoRA and Hugging Face**                              | Details and code for efficient training of large language models using LoRA and Hugging Face.                                                                                                 | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ashishpatel26/LLM-Finetuning/blob/main/1.Efficiently_train_Large_Language_Models_with_LoRA_and_Hugging_Face.ipynb) |

## Contributing ü§ù

Contributions are welcome! If you'd like to contribute to this project, feel free to open an issue or submit a pull request.

<!-- ## License üìù

This project is licensed under the [MIT License](LICENSE). -->

---

Created with ‚ù§Ô∏è by [Chirag](https://github.com/chiragjoshi12)
