# LLM-Finetuning

# PEFT Fine-Tuning Project üöÄ

Welcome to the PEFT (Pretraining-Evaluation Fine-Tuning) project repository! This project focuses on efficiently fine-tuning large language models using LoRA and Hugging Face's transformers library.

<!-- ![](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/images/trl_overview.png) -->

## Fine Tuning Notebook Table üìë

| Notebook Title                                                                                               | Description                                                                                                                                                                                   | Colab Badge                                                                                                                                                                                                                         |
| ------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Fine-tuning LLaMA with Lora**                              | Fine-tuning LLaMA on a Custom Dataset.                                                                                                 | [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/chiragjoshi12/LLM-Finetuning/blob/main/Fine_Tune_Llama_2_with_LoRa.ipynb) |

## Contributing ü§ù

Contributions are welcome! If you'd like to contribute to this project, feel free to open an issue or submit a pull request.

<!-- ## License üìù

This project is licensed under the [MIT License](LICENSE). -->

---

Created with ‚ù§Ô∏è by [Chirag](https://github.com/chiragjoshi12)
